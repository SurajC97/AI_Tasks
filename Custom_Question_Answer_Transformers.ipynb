{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9758c536c7c345beb999718bc713f958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_313e360b63624fc0bbf80b883b515eda",
              "IPY_MODEL_9608da504c494611977670e0bd5d2d75",
              "IPY_MODEL_1e137beef99844f59c1fe46dc9ccfe7c"
            ],
            "layout": "IPY_MODEL_eedc2926c7a746ae987f60f46e73c7cd"
          }
        },
        "313e360b63624fc0bbf80b883b515eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e295f5ec9545789a132e90fa0b9136",
            "placeholder": "​",
            "style": "IPY_MODEL_b92cd3f24c044ff18375718e170cf0e2",
            "value": "Map: 100%"
          }
        },
        "9608da504c494611977670e0bd5d2d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc5407174d74c96a0dea9b16403ff23",
            "max": 16000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5e392d276b64513993a24fa35c978b0",
            "value": 16000
          }
        },
        "1e137beef99844f59c1fe46dc9ccfe7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8d2332bb724c249b7bf685a54f0cde",
            "placeholder": "​",
            "style": "IPY_MODEL_a823848f155341c2b2d06ded31dc9c84",
            "value": " 16000/16000 [00:12&lt;00:00, 1219.38 examples/s]"
          }
        },
        "eedc2926c7a746ae987f60f46e73c7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "15e295f5ec9545789a132e90fa0b9136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92cd3f24c044ff18375718e170cf0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc5407174d74c96a0dea9b16403ff23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5e392d276b64513993a24fa35c978b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b8d2332bb724c249b7bf685a54f0cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a823848f155341c2b2d06ded31dc9c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "336097121e0448ed8fa2784e2159e046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8424dc99fec94ea5bde552f9d66027ac",
              "IPY_MODEL_1d17edac09bc4abbbfaa784af2ffa0f6",
              "IPY_MODEL_807fafb2a4234ba9b41278297fc04750"
            ],
            "layout": "IPY_MODEL_2edb566a0b6345aeaaa366d4548f5284"
          }
        },
        "8424dc99fec94ea5bde552f9d66027ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b93c329ee64924998a9f44fd168889",
            "placeholder": "​",
            "style": "IPY_MODEL_1ffb29c3c04d4b1f81580e7cfc1c2cfa",
            "value": "Map: 100%"
          }
        },
        "1d17edac09bc4abbbfaa784af2ffa0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a53a158ec947dbab58528c1eaa24a9",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e598adcb66304324a83a7604fa7cec2a",
            "value": 4000
          }
        },
        "807fafb2a4234ba9b41278297fc04750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2029378bc348ab80b97791cbba1b57",
            "placeholder": "​",
            "style": "IPY_MODEL_108fc594d7b7492c8267deee0745bbe5",
            "value": " 4000/4000 [00:04&lt;00:00, 938.15 examples/s]"
          }
        },
        "2edb566a0b6345aeaaa366d4548f5284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f5b93c329ee64924998a9f44fd168889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffb29c3c04d4b1f81580e7cfc1c2cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5a53a158ec947dbab58528c1eaa24a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e598adcb66304324a83a7604fa7cec2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe2029378bc348ab80b97791cbba1b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108fc594d7b7492c8267deee0745bbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvTVypfldHgT"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForQuestionAnswering\n",
        "from transformers import create_optimizer\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "-QAz7Gz1dj7-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading squad dataset\n",
        "\n",
        "squad = load_dataset(\"squad\", split=\"train[:20000]\")\n",
        "\n",
        "data = squad.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "jum3X3kndZnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing and initializing tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "Set_6dwJdfkO"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 400  # The maximum length of a feature.\n",
        "doc_stride = 120  # overlap between two part of the context."
      ],
      "metadata": {
        "id": "sHYCg0V1dfrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to truncate and map the start and end tokens of the answer to the context.\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "rbrPm405MZlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping data to the function.\n",
        "\n",
        "tokenized_datasets = data.map(\n",
        "    preprocess_function, batched=True, remove_columns=data[\"train\"].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9758c536c7c345beb999718bc713f958",
            "313e360b63624fc0bbf80b883b515eda",
            "9608da504c494611977670e0bd5d2d75",
            "1e137beef99844f59c1fe46dc9ccfe7c",
            "eedc2926c7a746ae987f60f46e73c7cd",
            "15e295f5ec9545789a132e90fa0b9136",
            "b92cd3f24c044ff18375718e170cf0e2",
            "5dc5407174d74c96a0dea9b16403ff23",
            "a5e392d276b64513993a24fa35c978b0",
            "7b8d2332bb724c249b7bf685a54f0cde",
            "a823848f155341c2b2d06ded31dc9c84",
            "336097121e0448ed8fa2784e2159e046",
            "8424dc99fec94ea5bde552f9d66027ac",
            "1d17edac09bc4abbbfaa784af2ffa0f6",
            "807fafb2a4234ba9b41278297fc04750",
            "2edb566a0b6345aeaaa366d4548f5284",
            "f5b93c329ee64924998a9f44fd168889",
            "1ffb29c3c04d4b1f81580e7cfc1c2cfa",
            "b5a53a158ec947dbab58528c1eaa24a9",
            "e598adcb66304324a83a7604fa7cec2a",
            "fe2029378bc348ab80b97791cbba1b57",
            "108fc594d7b7492c8267deee0745bbe5"
          ]
        },
        "id": "aFta2unVdZtw",
        "outputId": "68046b1a-1654-4553-82a0-44d34a95c5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9758c536c7c345beb999718bc713f958"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "336097121e0448ed8fa2784e2159e046"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the pretrained model for fine tuning.\n",
        "\n",
        "model = TFAutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgJ3NB8sdfue",
        "outputId": "2a1a1cb5-b77e-4dea-8e51-089b5e046587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForQuestionAnswering: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning parameter values\n",
        "\n",
        "learning_rate = 2e-4\n",
        "num_train_epochs = 10\n",
        "batch_size = 8"
      ],
      "metadata": {
        "id": "cSPHFgctdfw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare our train and test data.\n",
        "\n",
        "train_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,)\n",
        "\n",
        "validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,)"
      ],
      "metadata": {
        "id": "rX0WoBHJdfzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our optimizer\n",
        "\n",
        "total_train_steps = len(train_set) * num_train_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(init_lr=learning_rate, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ],
      "metadata": {
        "id": "o6nqAYhidf2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model.\n",
        "\n",
        "model.compile(optimizer=optimizer, jit_compile=True, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "tED_mxZKdf40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model.\n",
        "\n",
        "model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=num_train_epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZii8jgtebi2",
        "outputId": "895e2766-3556-451f-d6bc-fa3df22bd9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 767s 365ms/step - loss: 1.8616 - end_logits_accuracy: 0.5166 - start_logits_accuracy: 0.4949 - val_loss: 1.1846 - val_end_logits_accuracy: 0.6740 - val_start_logits_accuracy: 0.6352\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 736s 368ms/step - loss: 0.9832 - end_logits_accuracy: 0.7278 - start_logits_accuracy: 0.7009 - val_loss: 1.1589 - val_end_logits_accuracy: 0.6945 - val_start_logits_accuracy: 0.6628\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 703s 351ms/step - loss: 0.6212 - end_logits_accuracy: 0.8133 - start_logits_accuracy: 0.7951 - val_loss: 1.2377 - val_end_logits_accuracy: 0.6773 - val_start_logits_accuracy: 0.6547\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 742s 371ms/step - loss: 0.3976 - end_logits_accuracy: 0.8770 - start_logits_accuracy: 0.8643 - val_loss: 1.3580 - val_end_logits_accuracy: 0.6885 - val_start_logits_accuracy: 0.6575\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 736s 368ms/step - loss: 0.2603 - end_logits_accuracy: 0.9165 - start_logits_accuracy: 0.9092 - val_loss: 1.5965 - val_end_logits_accuracy: 0.6775 - val_start_logits_accuracy: 0.6450\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 737s 368ms/step - loss: 0.1736 - end_logits_accuracy: 0.9482 - start_logits_accuracy: 0.9379 - val_loss: 1.7017 - val_end_logits_accuracy: 0.6758 - val_start_logits_accuracy: 0.6510\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 736s 368ms/step - loss: 0.1279 - end_logits_accuracy: 0.9589 - start_logits_accuracy: 0.9556 - val_loss: 1.8345 - val_end_logits_accuracy: 0.6802 - val_start_logits_accuracy: 0.6553\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 703s 352ms/step - loss: 0.0931 - end_logits_accuracy: 0.9720 - start_logits_accuracy: 0.9669 - val_loss: 1.9855 - val_end_logits_accuracy: 0.6762 - val_start_logits_accuracy: 0.6467\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 742s 371ms/step - loss: 0.0716 - end_logits_accuracy: 0.9777 - start_logits_accuracy: 0.9749 - val_loss: 2.0236 - val_end_logits_accuracy: 0.6793 - val_start_logits_accuracy: 0.6562\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 738s 369ms/step - loss: 0.0577 - end_logits_accuracy: 0.9831 - start_logits_accuracy: 0.9806 - val_loss: 2.0989 - val_end_logits_accuracy: 0.6787 - val_start_logits_accuracy: 0.6532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x77fec0f49f60>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWtV3hn5Diz8",
        "outputId": "e4dafec3-a8a3-4af7-d8fe-ba24e82c3219"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model.\n",
        "\n",
        "model.save_pretrained('/content/drive/MyDrive/Exported_models/my_QA_model/my_model')"
      ],
      "metadata": {
        "id": "JlZZT-7kgUwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "\n",
        "mymodel = TFAutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/Exported_models/my_QA_model/my_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrf3LhtTvndv",
        "outputId": "11ead37d-6fac-41e9-e564-7dde9f50fdbb"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
            "\n",
            "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Exported_models/my_QA_model/my_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking input from user\n",
        "\n",
        "inp= input(\"Enter url: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73edda9-6e2d-4c52-8b07-d8ac6ef045dd",
        "id": "Lg5BWYhSwcTU"
      },
      "execution_count": 178,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter url: https://blog.datagran.io/posts/whats-ai-ml-and-dl-what-are-the-differences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetching page data and response.\n",
        "\n",
        "page= requests.get(inp)\n",
        "page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5334e9-0830-4360-eb0d-7e1c6f3b879f",
        "id": "TgVXu26ywcTV"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing the data\n",
        "\n",
        "soup= BeautifulSoup(page.content)\n",
        "full_context= str(soup.text.strip())\n",
        "full_context= full_context.replace('\\n','')"
      ],
      "metadata": {
        "id": "rZkVAFTvwcTW"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bef37954-7577-43c4-d302-abfd8d67ab02",
        "id": "kYqDLVEqwcTW"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What’s AI, ML and DL? What are the differences?THE BLOGTHE BLOGCATEGORY:Artificial IntelligenceTAGS:Artificial IntelligenceMachine LearningWhat’s AI, ML and DL? What are the differences?Necati DemirChief AI OfficerIt’s very common for a lot of people who jump into the world of AI to get drown in the terms and abbreviations. Artificial Intelligence? Machine Learning? Deep Learning? AI? ML? DL? … and many more. In this short article, Here is my overview about those keywords.\\u200dArtificial Intelligence (AI)\\u200dLet’s start with artificial intelligence (AI). I always prefer to describe AI as an umbrella term which covers everything in this world. It is not a technical method or a name of a specific algorithm.\\xa0 AI is a research field in computer science that focuses on developing methods which can perform tasks that a human can accomplish.\\xa0The term artificial intelligence was first coined by John McCarthy in 1956 and his definition was “the science and engineering of making intelligent machines”. Although this term was coined by John McCarthy, the concept was discussed many times including in one of the papers of Alan Turing. In his paper, he discusses the machines being able to simulate human beings and the ability to do intelligent things. Now, since we discussed what AI, is we can continue with other keywords.\\u200dMachine Learning (ML)\\u200dThe term machine learning (ML) was first coined by Arthur Samuel and he described this term with this definition in 1959: “field of study that gives computers the ability to learn without being explicitly programmed”. Although this is a very high-level definition of machine learning, it roughly explains what machine learning is. Before jumping into it, I want to provide a more technical definition and this was stated by Tom Mitchell’s: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.” Yes, I said, it is way more technical ;)Let’s start digging into the first definition to understand what machine learning is. Samuel mentions that if a computer has the ability to learn without explicitly programming, it is\\xa0 called machine learning. Explicitly programming means telling the computers what to do by providing exact rules. If you are responsible to write a software, you can’t leave a vague area, you need to give precise commands. Let’s say you are responsible to implement a software system for a robotic arm and you want it to move items from one bucket to another bucket. You have to provide the exact coordinates of the items so the robotic arm can go there and then you have to provide the exact details of the pressure so the robotic arm can handle it. And then, you have to provide the exact details of the destination coordinates so the robotic arm can move to that specific coordinate, and lastly, you have to provide information to release the item. The goal of machine learning is to complete those tasks without being explicitly programming.When we jump into the 2nd definition, we will see that Mitchell explains a program that can complete a task based on learning and some performance metrics. Let’s go to the previous robotic arm example again. If we can provide this robotic arm a metric like “number of successfully moved items from one bucket to another” and ask this program to increase the metric value by learning itself and using its historical experience in each trial-error session, we can call this a machine learning based program.I believe the previous two definitions make the definition of machine learning clear. But, if I have to explain in one simple sentence, I would describe it as: AI as an umbrella term that covers everything related to this world, ML is the technical part/mathematical part of this world.\\xa0\\u200dDeep Learning (DL)\\u200dFor the last couple of years, a new term became one of the most known terms in the AI world; deep learning. Deep learning is a subset of machine learning methods. Actually, deep learning methods are based on neural network methods (which is also a machine learning method) and those methods are around since the 1960s. Deep learning is, in very basic terms, is creating multiple layers of neural networks. This wouldn't be possible in the 1960s because of required process power and huge amount of data. With the help of GPUs, huge amount of process power and with huge amount of data, it is possible to create deep learning architectures now.Deep learning methods started taking attention in 2012, when a deep learning architecture named AlexNet became the winner of ImageNet competition. The error rate was 15% while the runner-up was 10% more. This was one of the milestones in deep learning history. The goal of ImageNet competition was to classify the images; this is a car, this is a cat, ... What seems normal to us was a giant step 7 years ago.After this accomplishment, many others followed. Google improved its translation service by replacing its statistical methods with deep learning methods. Microsoft successfully implemented a deep learning based speech recognition system which provided the similar accuracy as human transcribers.Although I gave only two example applications (translation and speech recognition), there are dozens of application fields that use deep learning; including computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs.ConclusionIn this article, I tried to provide the definitions of artificial intelligence, machine learning and deep learning. AI can be considered as an umbrella term of this world, ML is the technical part of this world and DL is the subset of ML which helped the progress of AI to jump to another level.TweetSubscribeEnter your email below to receive our weekly newsletter.EmailThank you! Your submission has been received!Oops! Something went wrong while submitting the form.Latest POSTSArtificial IntelligenceData Science 10X faster with AIByCarlos MendezData WorkflowsReal-time Machine Learning Model-APIsByCarlos MendezBetter togetherMade with LOVE in San FranciscoCompanyAbout usBlogCareersDevelopersFAQAcademyAlgorithmsDocumentationSlack CommunityResources+1 (350) 639-7035Terms & ConditionsPrivacy PolicyContactSocialTwitterLinkedInFacebookInstagramFor any request related to your personal information, please contact us here: legal@datagran.io44 Montgomery St. 3rd Floor, San Francisco CA 94104\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating chunks of context if context size is too large for tokenizer.\n",
        "\n",
        "big= False\n",
        "if len(full_context) > 500:\n",
        "  K= 6\n",
        "  splt_char='.'\n",
        "  temp = full_context.split(splt_char)\n",
        "  context_list= [splt_char.join(temp[i:i+K]) for i in range(0, len(temp), K)][:-1]\n",
        "  big = True"
      ],
      "metadata": {
        "id": "8MhF54eywcTY"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Going through each context chunk and extracting answer/response.\n",
        "\n",
        "def my_answer(context_list, question, tokenizer, mymodel):\n",
        "  temp=4\n",
        "\n",
        "  for context in context_list:\n",
        "\n",
        "    start_position=0\n",
        "    end_position=0\n",
        "\n",
        "    inputs = tokenizer([question], [context], return_tensors=\"np\")\n",
        "    outputs = mymodel(inputs)\n",
        "\n",
        "    start_position = np.argmax(outputs.start_logits[0])\n",
        "    end_position = np.argmax(outputs.end_logits[0])\n",
        "\n",
        "    if start_position<=end_position and outputs.start_logits[0][start_position]>temp:\n",
        "\n",
        "      start_position_final= start_position\n",
        "      end_position_final= end_position\n",
        "      inputs_final= inputs\n",
        "      temp= outputs.start_logits[0][start_position]\n",
        "\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  # Decoding tokens to form answers.\n",
        "  answer = inputs_final[\"input_ids\"][0, start_position_final: end_position_final + 1]\n",
        "  return tokenizer.decode(answer)"
      ],
      "metadata": {
        "id": "qWlo9S4Cvsn-"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get answer\n",
        "def get_answer(big):\n",
        "  if big:\n",
        "    print(my_answer(context_list, question, tokenizer, mymodel))\n",
        "  else:\n",
        "    inputs = tokenizer([question], [full_context], return_tensors=\"np\")\n",
        "    outputs = mymodel(inputs)\n",
        "    start_position = np.argmax(outputs.start_logits[0])\n",
        "    end_position = np.argmax(outputs.end_logits[0])\n",
        "    answer = inputs[\"input_ids\"][0, start_position: end_position + 1]\n",
        "    print(tokenizer.decode(answer))"
      ],
      "metadata": {
        "id": "SEApo8vvEXwL"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining question\n",
        "\n",
        "question= input(\"Enter your question: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwMUP_t6xwxc",
        "outputId": "aac9fc1e-17b7-469e-8a01-ce3a6d045bb1"
      },
      "execution_count": 183,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question: Who coined the term machine learning?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_answer(big)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osocryv7AbwH",
        "outputId": "9c104cdb-5126-4d09-f795-ea4deb88ec20"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arthur samuel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining another question\n",
        "\n",
        "question= \"What is deep learning?\"\n",
        "\n",
        "get_answer(big)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gULaL7JCv5v3",
        "outputId": "38fced73-4610-40df-9032-cf29afcb8ab0"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating multiple layers of neural networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIbjCC1XEvVH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}